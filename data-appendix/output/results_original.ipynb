{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liumukun/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-11d170ac1357>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  include.sellerfeedbackscore = logged_feedback\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/demeaned.csv\")\n",
    "df = data.groupby([\"id\", \"ispolice\", \"sellerfeedbackscore\", \"bidcount\", \"apple\", \"amazon\", \"samsung\", \"others\", \"increment_residual\"])[\"residual\"].apply(lambda x: x.values).reset_index()\n",
    "\n",
    "valid_bids = list(df[df.ispolice == 1].bidcount.value_counts().index)\n",
    "include = df[(df.bidcount > 1) & (df.bidcount.isin(valid_bids))]\n",
    "\n",
    "bids = list(include.residual)\n",
    "\n",
    "logged_feedback = np.log(include.sellerfeedbackscore+1)\n",
    "logged_feedback = transform_covariates(logged_feedback, 100)\n",
    "include.sellerfeedbackscore = logged_feedback\n",
    "include = include.reset_index(drop=True)\n",
    "\n",
    "o_covariates = np.array(include[[\"ispolice\", \"sellerfeedbackscore\"]])\n",
    "o_covariates = list([list(cov) for cov in o_covariates])\n",
    "o_covariates = [[c[0],round(c[1], 5)] for c in o_covariates]\n",
    "\n",
    "apple_covs = [c for i, c in enumerate(o_covariates) if i in list(include[include.apple == 1].index)]\n",
    "samsung_covs = [c for i, c in enumerate(o_covariates) if i in list(include[include.samsung == 1].index)]\n",
    "amazon_covs = [c for i, c in enumerate(o_covariates) if i in list(include[include.amazon == 1].index)]\n",
    "others_covs = [c for i, c in enumerate(o_covariates) if i in list(include[include.others == 1].index)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./final dumps/CMF_main.json\", \"r\") as f:\n",
    "    d = json.load(f)\n",
    "    covariates = d[\"covariates\"]\n",
    "    median_lower = d[\"lower\"]\n",
    "    median_upper = d[\"upper\"]\n",
    "    \n",
    "    covariates = [[c[0],round(c[1], 5)] for c in covariates]\n",
    "    median_lower = {f\"{[eval(k)[0], round(eval(k)[1],5)]}\": v for k, v in median_lower.items()}\n",
    "    median_upper = {f\"{[eval(k)[0], round(eval(k)[1],5)]}\": v for k, v in median_upper.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.90745165  0.28223717  0.10400445  0.04094814]\n",
      "[-0.9199388497314462, -0.8950663933139305, 0.13893647675033916, 0.38034447428177187, 0.10214789387783955, 0.10584955993725813, 0.026805688926432095, 0.050669398793987325]\n"
     ]
    }
   ],
   "source": [
    "def loss_function1(c):\n",
    "    cef = lambda cov: c[0]+c[1]*cov[0]+c[2]*cov[1]*(1-cov[0])+c[3]*cov[1]*cov[0]\n",
    "    return get_loss_function(covariates, median_upper, median_lower, cef)\n",
    "\n",
    "point1, interval1 = get_estimates(loss_function1, 4, [0,0.5,0,0])\n",
    "\n",
    "print(point1)\n",
    "print(interval1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummies specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3247559666026739, -0.29741491346275456, 0.38966097091661517, 0.49064331054688776, -0.37125561079858116, -0.10598501381650231, -0.3969580529112641, -0.04990031278250435]\n"
     ]
    }
   ],
   "source": [
    "percentile = lambda p: np.percentile(np.array(include.sellerfeedbackscore), p)\n",
    "\n",
    "estimates = []\n",
    "\n",
    "for i in range(2):\n",
    "    \n",
    "    covs1 = [c for c in covariates if c[1] >= percentile(0) and c[1] < percentile(91.5) and c[0] == i]\n",
    "    loss_function = lambda c: get_loss_function(covs1, median_upper, median_lower, lambda cov: c)\n",
    "    \n",
    "    point, interval = get_estimates(loss_function, 1, [0])\n",
    "    estimates += [c[0] for c in interval]\n",
    "    \n",
    "    covs1 = [c for c in covariates if c[1] >= percentile(91.5) and c[1] < percentile(100) and c[0] == i]\n",
    "    loss_function = lambda c: get_loss_function(covs1, median_upper, median_lower, lambda cov: c)\n",
    "    \n",
    "    point, interval = get_estimates(loss_function, 1, [0])\n",
    "    estimates += [c[0] for c in interval]\n",
    "        \n",
    "print(estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brand-specific specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.87786815  0.4391263   0.09566554  0.02321946]\n",
      "[-0.8999110385309034, -0.8569160993873751, 0.2516395994338509, 0.5768730653151491, 0.09241019762821258, 0.09874761328443689, 0.004821222465710407, 0.036827004722374206]\n"
     ]
    }
   ],
   "source": [
    "def loss_function3(c):\n",
    "    cef = lambda cov: c[0]+c[1]*cov[0]+c[2]*cov[1]*(1-cov[0])+c[3]*cov[1]*cov[0]\n",
    "    return get_loss_function(amazon_covs, median_upper, median_lower, cef)\n",
    "\n",
    "point3, interval3 = get_estimates(loss_function3, 4, [0,0.5,0,0])\n",
    "\n",
    "print(point3)\n",
    "print(interval3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.97612787  0.40452798  0.12601     0.04570228]\n",
      "[-1.0018857430455579, -0.949975114849752, -0.015397906670380532, 0.720817390988442, 0.1224278176621307, 0.1296752618436335, 0.004099837692607663, 0.07703735938009097]\n"
     ]
    }
   ],
   "source": [
    "def loss_function4(c):\n",
    "    cef = lambda cov: c[0]+c[1]*cov[0]+c[2]*cov[1]*(1-cov[0])+c[3]*cov[1]*cov[0]\n",
    "    return get_loss_function(samsung_covs, median_upper, median_lower, cef)\n",
    "\n",
    "point4, interval4 = get_estimates(loss_function4, 4, [0,0.5,0,0])\n",
    "\n",
    "print(point4)\n",
    "print(interval4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.77528482  0.49835632  0.08366161 -0.00210577]\n",
      "[-0.7971862885394333, -0.7531665086391135, 0.3638035833252901, 0.7504153249461836, 0.07998655868467609, 0.0873158659277836, -0.015460349953916024, 0.02292959844772547]\n"
     ]
    }
   ],
   "source": [
    "def loss_function5(c):\n",
    "    cef = lambda cov: c[0]+c[1]*cov[0]+c[2]*cov[1]*(1-cov[0])+c[3]*cov[1]*cov[0]\n",
    "    return get_loss_function(apple_covs, median_upper, median_lower, cef)\n",
    "\n",
    "point5, interval5 = get_estimates(loss_function5, 4, [0,0.5,0,0])\n",
    "\n",
    "print(point5)\n",
    "print(interval5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.07340031  0.50323414  0.13494833  0.03249643]\n",
      "[-1.1145233223056168, -1.0328194025802702, 0.35365344313474995, 0.6626504240258898, 0.13022434009197315, 0.13950684479554476, 0.01766539029380184, 0.048309660299615205]\n"
     ]
    }
   ],
   "source": [
    "def loss_function6(c):\n",
    "    cef = lambda cov: c[0]+c[1]*cov[0]+c[2]*cov[1]*(1-cov[0])+c[3]*cov[1]*cov[0]\n",
    "    return get_loss_function(others_covs, median_upper, median_lower, cef)\n",
    "\n",
    "point6, interval6 = get_estimates(loss_function6, 4, [0,0.5,0,0])\n",
    "\n",
    "print(point6)\n",
    "print(interval6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixed = [filename for filename in os.listdir(\"./final dumps\") if filename.startswith(\"bootstrap_main\")]\n",
    "\n",
    "results = []\n",
    "\n",
    "for name in prefixed:\n",
    "    with open(f\"./final dumps/{name}\", \"r\") as f:\n",
    "        d = json.load(f)\n",
    "        covariates = d[\"covariates\"]\n",
    "        median_lower = d[\"lower\"]\n",
    "        median_upper = d[\"upper\"]\n",
    "        \n",
    "        covariates = [[c[0],round(c[1], 5)] for c in covariates]\n",
    "        median_lower = {f\"{[eval(k)[0], round(eval(k)[1],5)]}\": v for k, v in median_lower.items()}\n",
    "        median_upper = {f\"{[eval(k)[0], round(eval(k)[1],5)]}\": v for k, v in median_upper.items()}\n",
    "        \n",
    "        results.append((covariates, median_lower, median_upper))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates1 = []\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    \n",
    "    def loss_function1(c):\n",
    "        cef = lambda cov: c[0]+c[1]*cov[0]+c[2]*cov[1]*(1-cov[0])+c[3]*cov[1]*cov[0]\n",
    "        return get_loss_function(result[0], result[2], result[1], cef)\n",
    "    \n",
    "    point1, interval1 = get_estimates(loss_function1, 4, [0,0.5,0,0])\n",
    "    \n",
    "    estimates1.append(interval1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence interval for variable 0:\n",
      "[-1.0810805468684106, -0.3010392487266563]\n",
      "95% confidence interval for variable 1:\n",
      "[-0.7828472164970424, 0.6867565956049403]\n",
      "95% confidence interval for variable 2:\n",
      "[0.02197846563836084, 0.1472108526984288]\n",
      "95% confidence interval for variable 3:\n",
      "[-0.03498061749570955, 0.1284245014492054]\n"
     ]
    }
   ],
   "source": [
    "conf_intervals1 = report_intervals(estimates1, 95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummies specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates2 = []\n",
    "\n",
    "percentile = lambda p: np.percentile(np.array(include.sellerfeedbackscore), p)\n",
    "\n",
    "for result in results:\n",
    "    \n",
    "    estimates = []\n",
    "\n",
    "    for i in range(2):\n",
    "\n",
    "        covs1 = [c for c in result[0] if c[1] >= percentile(0) and c[1] < percentile(91.5) and c[0] == i]\n",
    "        loss_function = lambda c: get_loss_function(covs1, result[2], result[1], lambda cov: c)\n",
    "\n",
    "        point, interval = get_estimates(loss_function, 1, [0])\n",
    "        estimates += [c[0] for c in interval]\n",
    "\n",
    "        covs1 = [c for c in result[0] if c[1] >= percentile(91.5) and c[1] < percentile(100) and c[0] == i]\n",
    "        loss_function = lambda c: get_loss_function(covs1, result[2], result[1], lambda cov: c)\n",
    "\n",
    "        point, interval = get_estimates(loss_function, 1, [0])\n",
    "        estimates += [c[0] for c in interval]\n",
    "\n",
    "    estimates2.append(estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence interval for variable 0:\n",
      "[-0.3299511941075753, 0.0020011543577281676]\n",
      "95% confidence interval for variable 1:\n",
      "[0.1408001864173434, 0.6334632345073752]\n",
      "95% confidence interval for variable 2:\n",
      "[-0.40295774739439705, 0.1452468826884603]\n",
      "95% confidence interval for variable 3:\n",
      "[-0.44990847742539486, 0.21725736384777597]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[-0.3299511941075753, 0.0020011543577281676],\n",
       " [0.1408001864173434, 0.6334632345073752],\n",
       " [-0.40295774739439705, 0.1452468826884603],\n",
       " [-0.44990847742539486, 0.21725736384777597]]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_intervals(estimates2, 95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brand-specific specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates_samsung = []\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    \n",
    "    covs = [c for c in samsung_covs if c in result[0]]\n",
    "    \n",
    "    def loss_function(c):\n",
    "        cef = lambda cov: c[0]*(1-cov[0])+c[1]*cov[0]+c[2]*cov[1]*(1-cov[0])+c[3]*cov[1]*cov[0]\n",
    "        return get_loss_function(covs, result[2], result[1], cef)\n",
    "    \n",
    "    point, interval = get_estimates(loss_function, 4, [0,0.4,0,0])\n",
    "    \n",
    "    estimates_samsung.append(interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence interval for variable 0:\n",
      "[-1.2758881815931227, -0.3615791727757852]\n",
      "95% confidence interval for variable 1:\n",
      "[-0.026594139194354622, 0.8574711294092471]\n",
      "95% confidence interval for variable 2:\n",
      "[0.02062497437988826, 0.16469691453406002]\n",
      "95% confidence interval for variable 3:\n",
      "[-0.10253137020437217, 0.0007102971548719609]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[-1.2758881815931227, -0.3615791727757852],\n",
       " [-0.026594139194354622, 0.8574711294092471],\n",
       " [0.02062497437988826, 0.16469691453406002],\n",
       " [-0.10253137020437217, 0.0007102971548719609]]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_intervals(estimates_samsung,95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates_amazon = []\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    \n",
    "    covs = [c for c in amazon_covs if c in result[0]]\n",
    "    \n",
    "    def loss_function(c):\n",
    "        cef = lambda cov: c[0]+c[1]*cov[0]+c[2]*cov[1]*(1-cov[0])+c[3]*cov[1]*cov[0]\n",
    "        return get_loss_function(covs, result[2], result[1], cef)\n",
    "    \n",
    "    point, interval = get_estimates(loss_function, 4, [0,0.5,0,0])\n",
    "    \n",
    "    estimates_amazon.append(interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence interval for variable 0:\n",
      "[-1.099374749563581, -0.2773724695036865]\n",
      "95% confidence interval for variable 1:\n",
      "[-0.922631325513298, 0.7236865015523338]\n",
      "95% confidence interval for variable 2:\n",
      "[0.01148470148998482, 0.146069248454594]\n",
      "95% confidence interval for variable 3:\n",
      "[-0.04049514732381121, 0.14019035697702847]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[-1.099374749563581, -0.2773724695036865],\n",
       " [-0.922631325513298, 0.7236865015523338],\n",
       " [0.01148470148998482, 0.146069248454594],\n",
       " [-0.04049514732381121, 0.14019035697702847]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_intervals(estimates_amazon,95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates_apple = []\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    \n",
    "    covs = [c for c in apple_covs if c in result[0]]\n",
    "    \n",
    "    def loss_function(c):\n",
    "        cef = lambda cov: c[0]+c[1]*cov[0]+c[2]*cov[1]*(1-cov[0])+c[3]*cov[1]*cov[0]\n",
    "        return get_loss_function(covs, result[2], result[1], cef)\n",
    "    \n",
    "    point, interval = get_estimates(loss_function, 4, [0,0.5,0,0])\n",
    "    \n",
    "    estimates_apple.append(interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence interval for variable 0:\n",
      "[-0.9935493722732301, -0.14813230265378377]\n",
      "95% confidence interval for variable 1:\n",
      "[-0.48172847049910655, 0.7998356595987787]\n",
      "95% confidence interval for variable 2:\n",
      "[0.02011073558705111, 0.13417857201164954]\n",
      "95% confidence interval for variable 3:\n",
      "[-0.045096466991176844, 0.07065553183450685]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[-0.9935493722732301, -0.14813230265378377],\n",
       " [-0.48172847049910655, 0.7998356595987787],\n",
       " [0.02011073558705111, 0.13417857201164954],\n",
       " [-0.045096466991176844, 0.07065553183450685]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_intervals(estimates_apple,95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates_others = []\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    \n",
    "    covs = [c for c in others_covs if c in others_covs]\n",
    "    \n",
    "    def loss_function(c):\n",
    "        cef = lambda cov: c[0]+c[1]*cov[0]+c[2]*cov[1]*(1-cov[0])+c[3]*cov[1]*cov[0]\n",
    "        return get_loss_function(covs, result[2], result[1], cef)\n",
    "    \n",
    "    point, interval = get_estimates(loss_function, 4, [0,0.5,0,0])\n",
    "    \n",
    "    estimates_others.append(interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence interval for variable 0:\n",
      "[-1.186827521014219, -0.3947472217454029]\n",
      "95% confidence interval for variable 1:\n",
      "[-0.36630234968898684, 0.6969546800087092]\n",
      "95% confidence interval for variable 2:\n",
      "[0.039267691345530445, 0.16125919728398544]\n",
      "95% confidence interval for variable 3:\n",
      "[-0.03233094722326156, 0.06687213340049457]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[-1.186827521014219, -0.3947472217454029],\n",
       " [-0.36630234968898684, 0.6969546800087092],\n",
       " [0.039267691345530445, 0.16125919728398544],\n",
       " [-0.03233094722326156, 0.06687213340049457]]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_intervals(estimates_others,95)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
