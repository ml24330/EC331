{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liumukun/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-b51866ad607b>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  include.sellerfeedbackscore = logged_feedback\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/demeaned.csv\")\n",
    "df = data.groupby([\"id\", \"ispolice\", \"sellerfeedbackscore\", \"bidcount\", \"apple\", \"amazon\", \"increment_residual\"])[\"residual\"].apply(lambda x: x.values).reset_index()\n",
    "\n",
    "valid_bids = list(df[df.ispolice == 1].bidcount.value_counts().index)\n",
    "include = df[(df.bidcount > 1) & (df.bidcount.isin(valid_bids))]\n",
    "\n",
    "bids = list(include.residual)\n",
    "\n",
    "logged_feedback = np.log(include.sellerfeedbackscore+1)\n",
    "logged_feedback = transform_covariates(logged_feedback, 100)\n",
    "include.sellerfeedbackscore = logged_feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./final dumps/CMF_alt1.json\", \"r\") as f:\n",
    "    d = json.load(f)\n",
    "    covariates_alt1 = d[\"covariates\"]\n",
    "    median_lower_alt1 = d[\"lower\"]\n",
    "    median_upper_alt1 = d[\"upper\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./final dumps/CMF_alt2.json\", \"r\") as f:\n",
    "    d = json.load(f)\n",
    "    covariates_alt2 = d[\"covariates\"]\n",
    "    median_lower_alt2 = d[\"lower\"]\n",
    "    median_upper_alt2 = d[\"upper\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.81777332 -0.0011764   0.10761677 -0.01448755]\n",
      "[-0.8296183835244818, -0.8058446667122274, -0.129167520875916, 0.09337747946225983, 0.1059223722652357, 0.10931882225878209, -0.02718347519855654, -0.005096622986215289]\n"
     ]
    }
   ],
   "source": [
    "def loss_function1_alt1(c):\n",
    "    cef = lambda cov: c[0]*(1-cov[0])+c[1]*cov[0]+c[2]*cov[1]*(1-cov[0])+c[3]*cov[1]*cov[0]\n",
    "    return get_loss_function(covariates_alt1, median_upper_alt1, median_lower_alt1, cef)\n",
    "\n",
    "point1_alt1, interval1_alt1 = get_estimates(loss_function1_alt1, 4, [0,0,0,0])\n",
    "\n",
    "print(point1_alt1)\n",
    "print(interval1_alt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function1_alt2(c):\n",
    "    cef = lambda cov: c[0]*(1-cov[0])+c[1]*cov[0]+c[2]*cov[1]*(1-cov[0])+c[3]*cov[1]*cov[0]\n",
    "    return get_loss_function(covariates_alt2, median_upper_alt2, median_lower_alt2, cef)\n",
    "\n",
    "point1_alt2, interval1_alt2 = get_estimates(loss_function1_alt2, 4, [0,0,0,0])\n",
    "\n",
    "print(point1_alt2)\n",
    "print(interval1_alt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummies specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.18271273 -0.30900403 -0.01051074  0.71791836]\n",
      "[-0.34324324642095877, -0.10492759784588929, -0.3220456999279932, -0.29597893543303044, -0.17111215767437113, 0.07326376010294665, 0.6712931080641543, 0.7625551397845775]\n"
     ]
    }
   ],
   "source": [
    "# percentile = lambda p: np.percentile(np.array(include.sellerfeedbackscore), p)\n",
    "\n",
    "def loss_function2_alt1(c):\n",
    "    def cef2(cov):\n",
    "        low = int(cov[1] >= percentile(0) and cov[1] < percentile(91.5))\n",
    "        high = int(cov[1] >= percentile(91.5) and cov[1] <= percentile(100))\n",
    "        return c[0]*cov[0] + c[1]*(1-cov[0]) + c[2]*cov[0]*high + c[3]*(1-cov[0])*high\n",
    "    \n",
    "    return get_loss_function(covariates_alt1, median_upper_alt1, median_lower_alt1, cef2)\n",
    "\n",
    "point2_alt1, interval2_alt1 = get_estimates(loss_function2_alt1, 4, [0,0,0,0])\n",
    "\n",
    "print(point2_alt1)\n",
    "print(interval2_alt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentile = lambda p: np.percentile(np.array(include.sellerfeedbackscore), p)\n",
    "\n",
    "def loss_function2_alt2(c):\n",
    "    def cef2(cov):\n",
    "        low = int(cov[1] >= percentile(0) and cov[1] < percentile(91.5))\n",
    "        high = int(cov[1] >= percentile(91.5) and cov[1] <= percentile(100))\n",
    "        return c[0]*cov[0] + c[1]*(1-cov[0]) + c[2]*cov[0]*high + c[3]*(1-cov[0])*high\n",
    "    \n",
    "    return get_loss_function(covariates_alt2, median_upper_alt2, median_lower_alt2, cef2)\n",
    "\n",
    "point2_alt2, interval2_alt2 = get_estimates(loss_function2_alt2, 4, [0,0,0,0])\n",
    "\n",
    "print(point2_alt2)\n",
    "print(interval2_alt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brand-specific specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixed = [filename for filename in os.listdir(\"./final dumps\") if filename.startswith(\"bootstrap_main\")]\n",
    "\n",
    "results = []\n",
    "\n",
    "for name in prefixed:\n",
    "    with open(f\"./final dumps/{name}\", \"r\") as f:\n",
    "        d = json.load(f)\n",
    "        covariates = d[\"covariates\"]\n",
    "        median_lower = d[\"lower\"]\n",
    "        median_upper = d[\"upper\"]\n",
    "        results.append((covariates, median_lower, median_upper))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates1 = []\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    \n",
    "    def loss_function1(c):\n",
    "        cef = lambda cov: c[0]*(1-cov[0])+c[1]*cov[0]+c[2]*cov[1]*(1-cov[0])+c[3]*cov[1]*cov[0]\n",
    "        return get_loss_function(result[0], result[1], result[2], cef)\n",
    "    \n",
    "    point1, interval1 = get_estimates(loss_function1, 4, [0,1,0,0])\n",
    "    \n",
    "    estimates1.append(interval1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence interval for variable 0:\n",
      "[-1.1824922339973507, -0.7549438439961645]\n",
      "95% confidence interval for variable 1:\n",
      "[-3.156568406570512, -1.319876876637475]\n",
      "95% confidence interval for variable 2:\n",
      "[0.021810833975781017, 0.08754510836105485]\n",
      "95% confidence interval for variable 3:\n",
      "[-0.004666130051292488, 0.10820753491071138]\n"
     ]
    }
   ],
   "source": [
    "report_intervals(estimates1, 95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummies specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates2 = []\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    \n",
    "    def loss_function2(c):\n",
    "        def cef2(cov):\n",
    "            low = int(cov[1] >= percentile(0) and cov[1] < percentile(91.5))\n",
    "            high = int(cov[1] >= percentile(91.5) and cov[1] <= percentile(100))\n",
    "            return c[0]*cov[0] + c[1]*(1-cov[0]) + c[2]*cov[0]*high + c[3]*(1-cov[0])*high\n",
    "\n",
    "        return get_loss_function(covariates, median_upper, median_lower, cef2)\n",
    "    \n",
    "    point2, interval2 = get_estimates(loss_function2, 4, [0,1,0,0])\n",
    "    \n",
    "    estimates2.append(interval2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_intervals(estimates1, 95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brand-specific specification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
